{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chardet\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import utils.data_processing_utils as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_data(data_frame,text_label,y_label,remove_text_with_substrings = None, remove_characters_from_text = None, remove_column_indexs =None, drop_na = False, remove_word_count_outlier=False,remove_word_length_outlier=False, remove_white_space = False):\n",
    "    \n",
    "    #Remove columns based off column index\n",
    "    if(remove_column_indexs != None):\n",
    "       data_frame.drop(data_frame.columns[remove_column_indexs],axis=1,inplace=True)\n",
    "\n",
    "    #Remove null values\n",
    "    if(drop_na):\n",
    "       data_frame.dropna()\n",
    "\n",
    "    #Remove white space\n",
    "    if(remove_white_space):\n",
    "        data_frame[text_label] = util.remove_block_of_white_space(data_frame[text_label])\n",
    "\n",
    "    #Remove rows with substring from the data   \n",
    "    if(remove_text_with_substrings != None):\n",
    "        for substring in remove_text_with_substrings:\n",
    "            data_frame = util.remove_text_with_substring(data_frame,data_frame[text_label],substring)\n",
    "\n",
    "    #Remove characters within the rows of the data  \n",
    "    if(remove_characters_from_text != None):\n",
    "        data_frame[text_label] = util.remove_character_from_text(data_frame[text_label],remove_characters_from_text)\n",
    "\n",
    "\n",
    "    #Remove outliers\n",
    "    if(remove_word_count_outlier == True or remove_word_length_outlier == True):\n",
    "        # Create word count and character count lists\n",
    "        word_count, char_count, ave_length =  util.getTextMetaInformation(data_frame,text_label)\n",
    "        word_count_outliers = []\n",
    "        word_length_outliers = []\n",
    "\n",
    "        if(remove_word_count_outlier):\n",
    "            #Get text indexes with short word count \n",
    "            short_word_count_outliers = util.get_outlier_indexes(word_count, 5, \"less\")\n",
    "            #Get text indexes with long word count \n",
    "            long_word_count_outliers = util.get_outlier_indexes(word_count, 35, \"greater\")\n",
    "            #Outliers for word count\n",
    "            word_count_outliers = np.append(short_word_count_outliers, long_word_count_outliers)\n",
    "        if(remove_word_length_outlier):\n",
    "            # Get long word length outliers\n",
    "            long_word_length_outliers = util.get_outlier_indexes(ave_length, 23, \"greater\")\n",
    "            # Get short word length outliers\n",
    "            short_word_length_outliers = util.get_outlier_indexes(ave_length, 3.5, \"less\")\n",
    "            #Outliers for word length\n",
    "            word_length_outliers = np.append(short_word_length_outliers, long_word_length_outliers)\n",
    "\n",
    "    if(remove_word_count_outlier and remove_word_length_outlier ):\n",
    "        outliers = np.append(word_count_outliers,word_length_outliers)       \n",
    "        data_frame = data_frame.drop(data_frame.index[outliers])\n",
    "\n",
    "    elif(remove_word_count_outlier and not remove_word_length_outlier):\n",
    "        outliers = word_count_outliers      \n",
    "        data_frame = data_frame.drop(data_frame.index[outliers])   \n",
    "\n",
    "    elif(not remove_word_count_outlier and remove_word_length_outlier):\n",
    "        outliers = word_length_outliers      \n",
    "        data_frame = data_frame.drop(data_frame.index[outliers])   \n",
    "\n",
    "    return data_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "author_label_name = \"username\"\n",
    "save_file_name = \"processed_data.csv\"\n",
    "text_label = \"raw_text\"\n",
    "file_name = \"authorship_dataset.csv\"\n",
    "remove_characters = ['ï', 'é', 'ñ', 'è', 'ö', 'æ', 'ô', 'â', 'á', 'à', 'ê', 'ë']\n",
    "remove_column_indexes =[0,1]\n",
    "remove_substrings_from_text = [\"RT\"]\n",
    "drop_na = True\n",
    "remove_word_count_outlier = False\n",
    "remove_word_length_outlier = False\n",
    "remove_white_space = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63019"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(file_name)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leobl\\AppData\\Local\\Temp\\ipykernel_28980\\456196336.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame[text_label] = util.remove_character_from_text(data_frame[text_label],remove_characters_from_text)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27873"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = process_data(data,text_label,author_label_name,remove_substrings_from_text,remove_characters,\n",
    "remove_column_indexes,drop_na,remove_word_count_outlier,remove_word_length_outlier,remove_white_space)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to excel\n",
    "df.to_csv(save_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
