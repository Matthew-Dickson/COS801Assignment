{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chardet\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import utils.data_processing_utils as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Processing data for modelling\n",
    "def process_data(data_frame,text_label='raw_text',y_label=\"username\",remove_url = True, \n",
    "remove_text_with_substrings = None, remove_characters_from_text = None, remove_column_indexs =None, \n",
    "drop_na = False, remove_word_count_outlier=[False,0,0],remove_word_length_outlier=[False,0,0], remove_white_space = False):\n",
    "\n",
    "\n",
    "    #Remove columns based off column index\n",
    "    if(remove_column_indexs != None):\n",
    "       data_frame.drop(data_frame.columns[remove_column_indexs],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "    #Remove white space\n",
    "    if(remove_white_space):\n",
    "        data_frame[text_label] = util.remove_block_of_white_space(data_frame[text_label])\n",
    "\n",
    "    if(remove_url):\n",
    "        data_frame[text_label] = data_frame[text_label].apply(util.remove_url)\n",
    "\n",
    "    #Remove rows with substring from the data   \n",
    "    if(remove_text_with_substrings != None):\n",
    "        for substring in remove_text_with_substrings:\n",
    "            data_frame = util.remove_text_with_substring(data_frame,data_frame[text_label],substring)\n",
    "\n",
    "    #Remove characters within the rows of the data  \n",
    "    if(remove_characters_from_text != None):\n",
    "        data_frame[text_label] = util.remove_character_from_text(data_frame[text_label],remove_characters_from_text)\n",
    "\n",
    "\n",
    "    #Remove outliers\n",
    "    if(remove_word_count_outlier[0] == True or remove_word_length_outlier[0] == True):\n",
    "        # Create word count and character count lists\n",
    "        word_count, char_count, ave_length =  util.getTextMetaInformation(data_frame,text_label)\n",
    "        word_count_outliers = []\n",
    "        word_length_outliers = []\n",
    "\n",
    "        if(remove_word_count_outlier):\n",
    "            #Get text indexes with short word count \n",
    "            short_word_count_outliers = util.get_outlier_indexes(word_count, remove_word_count_outlier[1], \"less\")\n",
    "            #Get text indexes with long word count \n",
    "            long_word_count_outliers = util.get_outlier_indexes(word_count, remove_word_count_outlier[2], \"greater\")\n",
    "            #Outliers for word count\n",
    "            word_count_outliers = np.append(short_word_count_outliers, long_word_count_outliers)\n",
    "        if(remove_word_length_outlier):\n",
    "            # Get long word length outliers\n",
    "            long_word_length_outliers = util.get_outlier_indexes(ave_length, remove_word_length_outlier[0], \"greater\")\n",
    "            # Get short word length outliers\n",
    "            short_word_length_outliers = util.get_outlier_indexes(ave_length, remove_word_length_outlier[1], \"less\")\n",
    "            #Outliers for word length\n",
    "            word_length_outliers = np.append(short_word_length_outliers, long_word_length_outliers)\n",
    "\n",
    "        if(remove_word_count_outlier and remove_word_length_outlier ):\n",
    "           \n",
    "            outliers = np.append(word_count_outliers,word_length_outliers)   \n",
    "            data_frame = data_frame.iloc[np.unique(outliers)]\n",
    "\n",
    "        elif(remove_word_count_outlier and not remove_word_length_outlier):\n",
    "            outliers = word_count_outliers      \n",
    "            data_frame = data_frame.iloc[np.unique(outliers)]  \n",
    "\n",
    "        elif(not remove_word_count_outlier and remove_word_length_outlier):\n",
    "            outliers = word_length_outliers      \n",
    "            data_frame = data_frame.iloc[np.unique(outliers)]       \n",
    "\n",
    "\n",
    "    #Remove any row with just empty text \n",
    "    filter = data_frame[text_label] != \"\"\n",
    "    data_frame = data_frame[filter]\n",
    "\n",
    "    #Remove null values\n",
    "    if(drop_na):\n",
    "       data_frame.dropna()\n",
    "       \n",
    "    return data_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper Parameters\n",
    "Y_LABEL = \"username\"\n",
    "SAVE_FILE_NAME = \"processed_data.csv\"\n",
    "X_LABEL = \"raw_text\"\n",
    "FILE_NAME = \"authorship_dataset.csv\"\n",
    "REMOVE_CHARACTERS = ['ï', 'é', 'ñ', 'è', 'ö', 'æ', 'ô', 'â', 'á', 'à', 'ê', 'ë']\n",
    "REMOVE_COLUMNN_INDEXES =[0,1]\n",
    "REMOVE_SUBSTRINGS_FROM_TEXT = [\"RT\",'\"']\n",
    "DROP_NA = True\n",
    "REMOVE_WORD_COUNT_OUTLIER = [False,0,0]\n",
    "REMOVE_WORD_LENGTH_OUTLIER = [False,0,0]\n",
    "REMOVE_WHITE_SPACE = True\n",
    "REMOVE_URLS = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63019"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(FILE_NAME)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63019\n"
     ]
    }
   ],
   "source": [
    "df = process_data(data_frame = data,text_label= X_LABEL,y_label=Y_LABEL, remove_url=REMOVE_URLS, remove_text_with_substrings=REMOVE_SUBSTRINGS_FROM_TEXT,\n",
    "remove_characters_from_text=REMOVE_CHARACTERS,remove_column_indexs=REMOVE_COLUMNN_INDEXES,drop_na=DROP_NA,remove_word_count_outlier = REMOVE_WORD_COUNT_OUTLIER,\n",
    "remove_word_length_outlier=REMOVE_WORD_LENGTH_OUTLIER,remove_white_space=REMOVE_WHITE_SPACE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27417"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing white space in y label\n",
    "df[Y_LABEL] = df[Y_LABEL].str.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df[[X_LABEL,Y_LABEL]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to excel\n",
    "clean_df.to_csv(SAVE_FILE_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
